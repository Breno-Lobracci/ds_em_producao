{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0.0 Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import datetime\n",
    "import pandas   as pd\n",
    "import numpy    as np\n",
    "import seaborn  as sns\n",
    "import xgboost  as xgb\n",
    "import inflection\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats as ss\n",
    "from boruta import BorutaPy\n",
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML\n",
    "from tabulate import tabulate\n",
    "from sklearn.preprocessing import RobustScaler, MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression, Lasso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 0.1 Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_absolute_percentage_error( y, yhat ):\n",
    "    return np.mean( np.abs( ( y - yhat) / y ) )\n",
    "\n",
    "def ml_error (model_name, y, yhat):\n",
    "    mae  = mean_absolute_error(y, yhat)\n",
    "    mape = mean_absolute_percentage_error(y,yhat)\n",
    "    rmse = np.sqrt(mean_squared_error(y, yhat))\n",
    "\n",
    "    return pd.DataFrame( {'Model Name': model_name,\n",
    "                          'MAE' : mae,\n",
    "                          'MAPE' : mape,\n",
    "                          'RMSE': rmse}, index=[0] )\n",
    "\n",
    "\n",
    "def jupyter_settings():\n",
    "    \n",
    "    %matplotlib inline\n",
    "    %pylab inline\n",
    "    \n",
    "    plt.style.use( 'bmh' )\n",
    "    plt.rcParams['figure.figsize'] = [25, 12]\n",
    "    plt.rcParams['font.size'] = 24\n",
    "    display( HTML( '<style>.container { width:100% !important; }</style>') )\n",
    "    pd.options.display.max_columns = None\n",
    "    pd.options.display.max_rows = None\n",
    "    pd.set_option( 'display.expand_frame_repr', False )\n",
    "    sns.set()\n",
    "\n",
    "def cramer_v( x, y):\n",
    "    cm = pd.crosstab(x, y).values\n",
    "    n = cm.sum()\n",
    "    r, k, = cm.shape\n",
    "    chi2 = ss.chi2_contingency( cm )[0]\n",
    "    chi2corr = max(0,chi2 - (k-1)*(r-1)/(n-1))\n",
    "    kcorr = k - (k-1)**2/(n-1)\n",
    "    rcorr = r - (r-1)**2/(n-1)\n",
    "    \n",
    "    return np.sqrt( (chi2corr/n) / (min(kcorr-1,rcorr-1) ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jupyter_settings()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 0.2 Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sales_raw = pd.read_csv('data/train.csv', low_memory = False)\n",
    "df_store_raw = pd.read_csv('data/store.csv', low_memory= False)\n",
    "\n",
    "# merge\n",
    "\n",
    "df_raw = pd.merge(df_sales_raw, df_store_raw, how='left', on='Store')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 1.0 Descrição dos Dados "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df_raw.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Rename Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_old = ['Store', 'DayOfWeek', 'Date', 'Sales', 'Customers', 'Open', 'Promo',\n",
    "       'StateHoliday', 'SchoolHoliday', 'StoreType', 'Assortment', 'CompetitionDistance',\n",
    "         'CompetitionOpenSinceMonth','CompetitionOpenSinceYear','Promo2', 'Promo2SinceWeek',\n",
    "       'Promo2SinceYear', 'PromoInterval']\n",
    "\n",
    "snakecase = lambda x: inflection.underscore( x )\n",
    "\n",
    "cols_new = list(map( snakecase, cols_old ))\n",
    "\n",
    "# rename\n",
    "\n",
    "df1.columns = cols_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Data Dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of Rows: {}' .format(df1.shape[0]))\n",
    "print('Number of Columns: {}' .format(df1.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Data Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['date'] = pd.to_datetime( df1['date'])\n",
    "df1.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Check NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 Fillout NA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#competition_distance\n",
    "df1['competition_distance'] = df1['competition_distance'].apply(lambda x: 200000.0 if math.isnan(x) else x)\n",
    "#competition_open_since_month\n",
    "df1['competition_open_since_month'] = df1.apply(lambda x: x['date'].month if math.isnan(x['competition_open_since_month']) else x['competition_open_since_month'], axis=1)\n",
    "#competition_open_since_year\n",
    "df1['competition_open_since_year'] = df1.apply(lambda x: x['date'].year if math.isnan(x['competition_open_since_year']) else x['competition_open_since_year'], axis=1)    \n",
    "#promo2_since_week            \n",
    "df1['promo2_since_week'] = df1.apply(lambda x: x['date'].week if math.isnan(x['promo2_since_week']) else x['promo2_since_week'], axis=1)\n",
    "#promo2_since_year              \n",
    "df1['promo2_since_year'] = df1.apply(lambda x: x['date'].year if math.isnan(x['promo2_since_year']) else x['promo2_since_year'], axis=1)\n",
    "#promo_interval\n",
    "month_map = {1: 'Jan', 2: 'Feb', 3: 'Mar',4: 'Apr', 5: 'May', 6:'Jun', 7: 'Jul', 8: 'Aug', 9: 'Sep', 10: 'Oct', 11: 'Nov', 12: 'Dec'  }\n",
    "\n",
    "df1['promo_interval'].fillna(0, inplace= True)\n",
    "\n",
    "df1['month_map'] = df1['date'].dt.month.map( month_map )\n",
    "\n",
    "df1['is_promo'] = df1[['promo_interval', 'month_map']].apply(lambda x: 0 if x['promo_interval']==0 else 1 if x['month_map'] in x['promo_interval'].split(',') else 0, axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.6 Change Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# competition\n",
    "df1['competition_open_since_month'] = df1['competition_open_since_month'].astype(int)\n",
    "df1['competition_open_since_year'] = df1['competition_open_since_year'].astype(int)\n",
    "\n",
    "#promo2\n",
    "df1['promo2_since_week'] = df1['promo2_since_week'].astype(int)\n",
    "df1['promo2_since_year'] = df1['promo2_since_year'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.7 Descriptive Statistical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_attributes = df1.select_dtypes( include=['int64', 'float64', 'int32'])\n",
    "cat_attributes = df1.select_dtypes( exclude=['int64', 'float64', 'datetime64[ns]','int32'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.7.1 Numerical Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Central Tendency  - mean, median \n",
    "ct1 = pd.DataFrame(num_attributes.apply( np.mean )).T\n",
    "ct2 = pd.DataFrame(num_attributes.apply( np.median )).T\n",
    "\n",
    "# Dispersion - std, min, max, range, skew, kurtosis\n",
    "d1 = pd.DataFrame(num_attributes.apply( np.std )).T\n",
    "d2 = pd.DataFrame(num_attributes.apply( min )).T\n",
    "d3 = pd.DataFrame(num_attributes.apply( max )).T\n",
    "d4 = pd.DataFrame(num_attributes.apply( lambda x: x.max() - x.min() ) ).T\n",
    "d5 = pd.DataFrame(num_attributes.apply( lambda x: x.skew() ) ).T\n",
    "d6 = pd.DataFrame(num_attributes.apply( lambda x: x.kurtosis() ) ).T\n",
    "\n",
    "# Concatenate\n",
    "m = pd.concat( [ d2, d3, d4, ct1, ct2, d1, d5, d6]).T.reset_index()\n",
    "m.columns = ['attributes','min','max','range','mean','median','std','skew','kurtosis']\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot( df1['competition_distance'] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.7.2 Category Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_attributes.apply( lambda x: x.unique().shape[0] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definindo o tamanho da figura\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "# Selecionando os dados\n",
    "aux1 = df1[(df1['state_holiday'] != '0') & (df1['sales'] > 0)]\n",
    "\n",
    "# Criando os subplots e boxplots\n",
    "plt.subplot(1, 3, 1)\n",
    "sns.boxplot(x='state_holiday', y='sales', data=aux1)\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "sns.boxplot(x='store_type', y='sales', data=aux1)\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "sns.boxplot(x='assortment', y='sales', data=aux1)\n",
    "\n",
    "# Mostrando os gráficos\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 2.0 Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df1.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Mapa Mental de Hipóteses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image('img/MindMapHyphotesis.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 2.2 Criação das Hipóteses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.1 Hipóteses Loja"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.** Lojas com maior quadro de colaboradores, deveriam vender mais.\n",
    "\n",
    "**2.** Lojas com maior capacidade de estoque, deveriam vender mais.\n",
    "\n",
    "**3.** Lojas com maior porte, deveriam vender mais.\n",
    "\n",
    "**4.** Lojas com maior sortimento, deveriam vender mais.\n",
    "\n",
    "**5.** Lojas com competidores mais próximos, deveriam vender mais.\n",
    "\n",
    "**6.** Lojas com competidores à mais tempo, deveriam vender mais.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.2 Hipóteses Produto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.** Lojas que investem mais em marketing, deveriam vender mais.\n",
    "\n",
    "**2.** Lojas que expõem melhor os produtos nas vitrines, deveriam vender mais.\n",
    "\n",
    "**3.** Lojas que tem preços menores nos produtos, deveriam vender mais.\n",
    "\n",
    "**4.** Lojas que tem preços menores por mais tempo, deveriam vender mais.\n",
    "\n",
    "**5.** Lojas com promoções mais agressivas (descontos maiores), deveriam vender mais.\n",
    "\n",
    "**6.** Lojas com promoções ativas por mais tempo, deveriam vender mais.\n",
    "\n",
    "**7.** Lojas com mais dias de promoção, deveriam vender mais.\n",
    "\n",
    "**8.** Lojas com mais promoções consecutivas, deveriam vender mais.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.3 Hipóteses Tempo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.** Lojas abertas durante o feriado de Natal, deveriam vender mais.\n",
    "\n",
    "**2.** Lojas deveriam vender mais ao longo dos anos.\n",
    "\n",
    "**3.** Lojas deveriam vender mais no segundo semestre do ano.\n",
    "\n",
    "**4.** Lojas deveriam vender mais depois do dia 10 de cada mês.\n",
    "\n",
    "**5.** Lojas deveriam vender menos aos finais de semana.\n",
    "\n",
    "**6.** Lojas deveriam vender menos durante os feriados escolares.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Lista Final de Hipóteses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.** Lojas com maior sortimento, deveriam vender mais.\n",
    "\n",
    "**2.** Lojas com competidores mais próximos, deveriam vender menos.\n",
    "\n",
    "**3.** Lojas com competidores à mais tempo, deveriam vender mais."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.** Lojas com promoções ativas por mais tempo, deveriam vender mais.\n",
    "\n",
    "**5.** Lojas com mais dias de promoção, deveriam vender mais.\n",
    "\n",
    "**6.** Lojas com mais promoções consecutivas, deveriam vender mais."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7.** Lojas abertas durante o feriado de Natal, deveriam vender mais.\n",
    "\n",
    "**8.** Lojas deveriam vender mais ao longo dos anos.\n",
    "\n",
    "**9.** Lojas deveriam vender mais no segundo semestre do ano.\n",
    "\n",
    "**10.** Lojas deveriam vender mais depois do dia 10 de cada mês.\n",
    "\n",
    "**11.** Lojas deveriam vender menos aos finais de semana.\n",
    "\n",
    "**12.** Lojas deveriam vender menos durante os feriados escolares.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 2.4 Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# year\n",
    "df2['year'] = df2['date'].dt.year\n",
    "\n",
    "# month\n",
    "df2['month'] = df2['date'].dt.month\n",
    "\n",
    "# day\n",
    "df2['day'] = df2['date'].dt.day\n",
    "\n",
    "# week of year\n",
    "df2['week_of_year'] = df2['date'].dt.isocalendar().week\n",
    "\n",
    "# year week\n",
    "df2['year_week'] = df2['date'].dt.strftime('%Y-%W')\n",
    "\n",
    "# competition since\n",
    "df2['competition_since'] = df2.apply( lambda x: datetime.datetime( year=x['competition_open_since_year'], month=x['competition_open_since_month'], day=1 ), axis=1)\n",
    "df2['competition_time_month'] = ((df2['date'] - df2['competition_since'])/30).apply( lambda x: x.days).astype( int)\n",
    "\n",
    "# promo since\n",
    "df2['promo_since'] = df2['promo2_since_year'].astype(str) + '-' + df2['promo2_since_week'].astype(str)\n",
    "df2['promo_since'] = df2['promo_since'].apply(lambda x: datetime.datetime.strptime (x + '-1', '%Y-%W-%w') - datetime.timedelta(days=7))\n",
    "df2['promo_time_week'] = ((df2['date'] - df2['promo_since'])/7).apply(lambda x: x.days ).astype(int)\n",
    "\n",
    "# assortment\n",
    "df2['assortment'] = df2['assortment'].apply(lambda x : 'basic' if x == 'a' else 'extra' if x == 'b' else 'extended')\n",
    "# state holiday\n",
    "\n",
    "df2['state_holiday'] = df2['state_holiday'].apply(lambda x: 'public_holiday' if x == 'a' else 'easter_holiday' if x == 'b' else 'christmas' if x == 'c' else 'regular_day')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 3.0 Filtragem de Variáveis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df2.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Filtragem das Linhas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df3[(df3['open'] != 0) & (df3['sales'] > 0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Seleção das Colunas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_drop = ['customers', 'open', 'promo_interval', 'month_map']\n",
    "\n",
    "df3 = df3.drop( cols_drop, axis = 1 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 4.0 Análise Explorátoria dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = df3.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Análise Univariáda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 4.1.1 Response Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(df4['sales'], kde=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 4.1.2 Numerical Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_attributes.hist( bins=25 );"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 4.1.3 Categorical Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4['store_type'].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# state_holiday\n",
    "plt.subplot( 3, 2, 1 )\n",
    "a = df4[df4['state_holiday'] != 'regular_day']\n",
    "sns.countplot(x= a['state_holiday'])\n",
    "\n",
    "plt.subplot( 3, 2, 2 )\n",
    "sns.kdeplot(df4[df4['state_holiday'] == 'public_holiday']['sales'],label='public_holiday' ,fill = True)\n",
    "sns.kdeplot(df4[df4['state_holiday'] == 'easter_holiday']['sales'],label='easter_holiday' ,fill = True)\n",
    "sns.kdeplot(df4[df4['state_holiday'] == 'christmas']['sales'],label='christmas' ,fill = True)\n",
    "plt.legend()\n",
    "# store_type\n",
    "plt.subplot( 3, 2, 3 )\n",
    "sns.countplot(x=df4['store_type'])\n",
    "\n",
    "plt.subplot( 3, 2, 4 )\n",
    "sns.kdeplot(df4[df4['store_type'] == 'a']['sales'],label='a' ,fill = True)\n",
    "sns.kdeplot(df4[df4['store_type'] == 'b']['sales'],label='b' ,fill = True)\n",
    "sns.kdeplot(df4[df4['store_type'] == 'c']['sales'],label='c' ,fill = True)\n",
    "sns.kdeplot(df4[df4['store_type'] == 'd']['sales'],label='d' ,fill = True)\n",
    "plt.legend()\n",
    "\n",
    "# assortment\n",
    "plt.subplot( 3, 2, 5 )\n",
    "sns.countplot(x=df4['assortment'])\n",
    "\n",
    "plt.subplot( 3, 2, 6 )\n",
    "sns.kdeplot(df4[df4['assortment'] == 'extended']['sales'],label='extended' ,fill = True)\n",
    "sns.kdeplot(df4[df4['assortment'] == 'basic']['sales'],label='basic' ,fill = True)\n",
    "sns.kdeplot(df4[df4['assortment'] == 'extra']['sales'],label='extra' ,fill = True)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Análise Bivariada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### **H1.** Lojas com maior sortimento, deveriam vender mais.\n",
    "**VERDADE**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aux1 = df4[['assortment', 'sales']].groupby('assortment').mean().reset_index()\n",
    "\n",
    "sns.barplot( x='assortment', y='sales', data= aux1 );\n",
    "\n",
    "aux2 = df4[['year_week', 'assortment', 'sales']].groupby(['year_week', 'assortment']).mean().reset_index()\n",
    "aux2.pivot(index= 'year_week', columns='assortment', values='sales').plot()\n",
    "\n",
    "aux3 = aux2[aux2['assortment'] == 'extra']\n",
    "\n",
    "aux3.pivot(index= 'year_week', columns='assortment', values='sales').plot()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### **H2.** Lojas com competidores mais próximos, deveriam vender menos.\n",
    "**FALSA** Lojas com COMPETIDORES MAIS PRÓXIMOS vendem MAIS.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aux1 = df4[['competition_distance','sales']].groupby('competition_distance').sum().reset_index()\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "sns.scatterplot(x = 'competition_distance', y= 'sales', data = aux1);\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "bins = list(np.arange(0, 20000, 1000))\n",
    "aux1['competition_distance_binned'] = pd.cut( aux1['competition_distance'], bins = bins )\n",
    "aux2 = aux1[['competition_distance_binned', 'sales']].groupby('competition_distance_binned').sum().reset_index()\n",
    "sns.barplot(x='competition_distance_binned', y='sales', data = aux2);\n",
    "\n",
    "plt.xticks(rotation = 90);\n",
    "plt.subplot(1, 3, 3)\n",
    "\n",
    "# Selecionar apenas as colunas numéricas para o cálculo da correlação\n",
    "numeric_columns = aux1.select_dtypes(include=['float64', 'int64']).columns\n",
    "\n",
    "# Calcular a matriz de correlação apenas para as colunas numéricas\n",
    "correlation_matrix = aux1[numeric_columns].corr(method='pearson')\n",
    "\n",
    "# Plotar a matriz de correlação\n",
    "sns.heatmap(correlation_matrix, annot=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### **H3.** Lojas com competidores à mais tempo, deveriam vender mais.\n",
    "**FALSA** Lojas com COMPETIDORES à mais tempo vendem MENOS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(1, 3, 1)\n",
    "aux1 = df4[['competition_time_month','sales']].groupby('competition_time_month').sum().reset_index()\n",
    "aux2 = aux1[(aux1['competition_time_month'] < 120) & (aux1['competition_time_month'] != 0)]\n",
    "sns.barplot(x='competition_time_month',y='sales', data= aux2);\n",
    "plt.xticks(rotation = 90);\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "sns.regplot(x='competition_time_month',y='sales', data= aux2);\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "\n",
    "sns.heatmap(aux1.corr(method='pearson'), annot=True);\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### **H4.** Lojas com promoções ativas por mais tempo, deveriam vender mais.\n",
    "**FALSA** Lojas com promoções ativas por mais tempo vendem menos, depois de um certo período de promoção."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aux1 = df4[['promo_time_week', 'sales']].groupby( 'promo_time_week').sum().reset_index()\n",
    "\n",
    "grid = GridSpec( 2, 3)\n",
    "\n",
    "\n",
    "plt.subplot(grid[0,0])\n",
    "aux2 = aux1[aux1['promo_time_week'] > 0] # promo extendido\n",
    "sns.barplot( x= 'promo_time_week', y='sales', data=aux2);\n",
    "plt.xticks(rotation=90);\n",
    "\n",
    "plt.subplot(grid[0,1])\n",
    "sns.regplot( x= 'promo_time_week', y='sales', data=aux2);\n",
    "\n",
    "plt.subplot(grid[1,0])\n",
    "aux3 = aux1[aux1['promo_time_week'] < 0] # promo regular\n",
    "sns.barplot( x= 'promo_time_week', y='sales', data=aux3);\n",
    "plt.xticks(rotation=90);\n",
    "\n",
    "plt.subplot(grid[1,1])\n",
    "sns.regplot( x= 'promo_time_week', y='sales', data=aux3);\n",
    "\n",
    "plt.subplot(grid[:,2])\n",
    "sns.heatmap(aux1.corr( method='pearson'), annot=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <s>**H5.** Lojas com mais dias de promoção, deveriam vender mais.<s>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### **H6.** Lojas com mais promoções consecutivas, deveriam vender mais.\n",
    "**FALSA** Lojas com mais promoções consecutivas, vendem menos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4[['promo', 'promo2', 'sales']].groupby(['promo', 'promo2']).sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aux1 = df4[(df4['promo'] == 1) & (df4['promo2'] == 1)][['year_week', 'sales']].groupby('year_week').sum().reset_index()\n",
    "ax = aux1.plot()\n",
    "\n",
    "aux2 = df4[(df4['promo'] == 1) & (df4['promo2'] == 0)][['year_week', 'sales']].groupby('year_week').sum().reset_index()\n",
    "aux2.plot( ax=ax )\n",
    "\n",
    "ax.legend(labels=['Tradicional & Extendida', 'Extendida'] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### **H7.** Lojas abertas durante o feriado de natal deveriam vender mais.\n",
    "**FALSA** Porque lojas abertas durante o feriado do Natal vendem menos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aux = df4[df4['state_holiday'] != 'regular_day']\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "aux1 = aux[['state_holiday', 'sales']].groupby('state_holiday').sum().reset_index()\n",
    "sns.barplot(x='state_holiday', y='sales', data=aux1);\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "aux2 = aux[['year', 'state_holiday', 'sales']].groupby(['year','state_holiday']).sum().reset_index()\n",
    "sns.barplot(x='year', y='sales', hue='state_holiday', data=aux2);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### **H8** Lojas deveriam vender mais ao longo dos anos.\n",
    "**FALSA** Lojas vendem menos ao longo dos anos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aux1 = df4[['year','sales']].groupby('year').sum().reset_index()\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "sns.barplot(x='year', y='sales', data=aux1);\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "sns.regplot(x='year', y='sales', data=aux1);\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "sns.heatmap(aux1.corr(method ='pearson'), annot=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### **H9.** Lojas deveriam vender mais no segundo semestre do ano.\n",
    "**FALSA** Lojas vendem menos no segundo semestre do ano\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aux1 = df4[['month','sales']].groupby('month').sum().reset_index()\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "sns.barplot(x='month', y='sales', data=aux1);\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "sns.regplot(x='month', y='sales', data=aux1);\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "sns.heatmap(aux1.corr(method ='pearson'), annot=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### **10.** Lojas deveriam vender mais depois do dia 10 de cada mês.\n",
    "**VERDADEIRA** Lojas vendem mais depois do dia 10 de cada mês."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aux1 = df4[['day','sales']].groupby('day').sum().reset_index()\n",
    "\n",
    "plt.subplot(2, 2, 1)\n",
    "sns.barplot(x='day', y='sales', data=aux1);\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "sns.regplot(x='day', y='sales', data=aux1);\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "sns.heatmap(aux1.corr(method ='pearson'), annot=True);\n",
    "\n",
    "aux1['before_after'] = aux1['day'].apply( lambda x: 'before_10_days' if x <= 10 else 'after_10_days')\n",
    "aux2 = aux1[['before_after', 'sales']].groupby('before_after').sum().reset_index()\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "sns.barplot(x='before_after', y='sales', data=aux2);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### **H11.** Lojas deveriam vender menos aos finais de semana.\n",
    "**VERDADEIRA** Lojas vendem menos nos finais de semana.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aux1 = df4[['day_of_week','sales']].groupby('day_of_week').sum().reset_index()\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "sns.barplot(x='day_of_week', y='sales', data=aux1);\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "sns.regplot(x='day_of_week', y='sales', data=aux1);\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "sns.heatmap(aux1.corr(method ='pearson'), annot=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### **H12.** Lojas deveriam vender menos durante os feriados escolares.\n",
    "**VERDADIRA** Lojas vendem mais durante os feriados escolares, exceto os meses de Julho e Agosto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aux1 = df4[['school_holiday', 'sales']].groupby('school_holiday').sum().reset_index()\n",
    "\n",
    "plt.subplot(2, 1, 1)\n",
    "sns.barplot(x='school_holiday', y='sales', data=aux1);\n",
    "\n",
    "aux2 = df4[['month','school_holiday', 'sales']].groupby(['month','school_holiday']).sum().reset_index()\n",
    "plt.subplot(2, 1, 2)\n",
    "sns.barplot(x='month', y='sales', hue='school_holiday', data=aux2);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 4.2.1 Resumo das Hipoteses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tab = [['Hipoteses', 'Conclusão', 'Relevância'],\n",
    "       ['H1', 'Verdadeira', 'Baixa'],\n",
    "       ['H2', 'Falsa', 'Media'],\n",
    "       ['H3', 'Falsa', 'Media'],\n",
    "       ['H4', 'Falsa', 'Baixa'],\n",
    "       ['H5', '-', '-'],\n",
    "       ['H6', 'Falsa', 'Baixa'],\n",
    "       ['H7', 'Falsa', 'Media'],\n",
    "       ['H8', 'Falsa', 'Alta'],\n",
    "       ['H9', 'Falsa', 'Alta'],\n",
    "       ['H10', 'Verdadeira', 'Alta'],\n",
    "       ['H11', 'Verdadeira', 'Alta'],\n",
    "       ['H12', 'Verdadeira', 'Baixa'],\n",
    "      ]\n",
    "\n",
    "print(tabulate(tab, headers='firstrow'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Análise Multivariada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 4.3.1 Numerical Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation = num_attributes.corr( method = 'pearson' )\n",
    "sns.heatmap( correlation, annot=True );"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 4.3.2 Categorical Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only categorical data\n",
    "a = df4.select_dtypes( include ='object' )\n",
    "\n",
    "# Calculate Cramer V\n",
    "a1 = cramer_v(a['state_holiday'], a['state_holiday'])\n",
    "a2 = cramer_v(a['state_holiday'], a['store_type'])\n",
    "a3 = cramer_v(a['state_holiday'], a['assortment'])\n",
    "\n",
    "a4 = cramer_v(a['store_type'], a['state_holiday'])\n",
    "a5 = cramer_v(a['store_type'], a['store_type'])\n",
    "a6 = cramer_v(a['store_type'], a['assortment'])\n",
    "\n",
    "a7 = cramer_v(a['assortment'], a['state_holiday'])\n",
    "a8 = cramer_v(a['assortment'], a['store_type'])\n",
    "a9 = cramer_v(a['assortment'], a['assortment'])\n",
    "\n",
    "# Final Dataset\n",
    "d= pd.DataFrame( {'state_holiday' : [a1, a2, a3],\n",
    "               'store_type' : [a4, a5, a6],\n",
    "               'assortment' : [a7, a8, a9]})\n",
    "\n",
    "d = d.set_index( d.columns )\n",
    "\n",
    "sns.heatmap(d, annot=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 5.0 Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5 = df4.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 5.1 Normalização"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Rescalling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs = RobustScaler()\n",
    "mms = MinMaxScaler()\n",
    "\n",
    "# competition distance\n",
    "df5['competition_distance'] = rs.fit_transform( df5[['competition_distance']].values )\n",
    "\n",
    "# competition time month\n",
    "df5['competition_time_month'] = rs.fit_transform( df5[['competition_time_month']].values )\n",
    "\n",
    "# promo time week\n",
    "df5['promo_time_week'] = mms.fit_transform( df5[['promo_time_week']].values )\n",
    "\n",
    "# year\n",
    "df5['year'] = mms.fit_transform( df5[['year']].values )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 Transformação"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3.1 Enconding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# state_holiday - One Hot Encodning\n",
    "df5 = pd.get_dummies(df5, prefix=['state_holiday'], columns=['state_holiday'], dtype=int)\n",
    "\n",
    "# store_type - Label Enconding\n",
    "le = LabelEncoder()\n",
    "df5['store_type'] = le.fit_transform( df5['store_type'] )\n",
    "\n",
    "# assortment - Ordinal Enconding\n",
    "assortment_dict = {'basic': 1, 'extra': 2, 'extended':3}\n",
    "df5['assortment'] = df5['assortment'].map(assortment_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3.2 Response Variable Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5['sales'] = np.log1p( df5['sales'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3.3 Nature Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# month\n",
    "df5['month_sin'] = df5['month'].apply( lambda x: np.sin( x * (2. * np.pi/12)))\n",
    "df5['month_cos'] = df5['month'].apply( lambda x: np.cos( x * (2. * np.pi/12)))\n",
    "\n",
    "# day\n",
    "df5['day_sin'] = df5['day'].apply( lambda x: np.sin( x * (2. * np.pi/30)))\n",
    "df5['day_cos'] = df5['day'].apply( lambda x: np.cos( x * (2. * np.pi/30)))\n",
    "\n",
    "# week of year\n",
    "df5['week_of_year_sin'] = df5['week_of_year'].apply( lambda x: np.sin( x * (2. * np.pi/52)))\n",
    "df5['week_of_year_cos'] = df5['week_of_year'].apply( lambda x: np.cos( x * (2. * np.pi/52)))\n",
    "\n",
    "# day of week\n",
    "df5['day_of_week_sin'] = df5['day_of_week'].apply( lambda x: np.sin( x * (2. * np.pi/7)))\n",
    "df5['day_of_week_cos'] = df5['day_of_week'].apply( lambda x: np.cos( x * (2. * np.pi/7)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.0 Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df6 = df5.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1 Split Dataframe in to training and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df6.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_drop = ['week_of_year', 'day', 'month','day_of_week', 'promo_since','competition_since', 'year_week']\n",
    "df6 = df6.drop(cols_drop, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df6[['store', 'date']].groupby('store').max().reset_index()['date'][0] - datetime.timedelta(days=6*7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Dataset\n",
    "X_train = df6[df6['date'] < '2015-06-19']\n",
    "y_train = X_train['sales']\n",
    "\n",
    "# Test Dataset with last 6 weeks of sales\n",
    "X_test = df6[df6['date'] >= '2015-06-19']\n",
    "y_test = X_test['sales']\n",
    "\n",
    "print('Training Min Date: {}' .format(X_train['date'].min()))\n",
    "print('Training Max Date: {}' .format(X_train['date'].max()))\n",
    "\n",
    "print('\\nTest Min Date: {}' .format(X_test['date'].min()))\n",
    "print('Test Max Date: {}' .format(X_test['date'].max()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2 Boruta as Feature Selector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training and test dataset for Boruta\n",
    "#X_train_n = X_train.drop( ['date', 'sales'], axis=1  ).values\n",
    "#y_train_n = y_train.values.ravel()\n",
    "# define Random Forest\n",
    "#rf = RandomForestRegressor( n_jobs=-1 )\n",
    "# define Boruta\n",
    "#boruta = BorutaPy( rf, n_estimators='auto', verbose=2, random_state=42 ).fit(X_train_n, y_train_n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2.1 Best Features from Boruta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cols_selected = boruta.support_.tolist()\n",
    "## best features\n",
    "#X_train_fs = X_train.drop(['date', 'sales'], axis = 1)\n",
    "#cols_selected_boruta = X_train_fs.iloc[:, cols_selected].columns.tolist()\n",
    "#not selected boruta\n",
    "#cols_not_selected_boruta = list(np.setdiff1d(X_train_fs.columns, cols_selected_boruta))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.3 Manual Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_selected_boruta = [\n",
    "     'store',\n",
    "     'promo',\n",
    "     'store_type',\n",
    "     'assortment',\n",
    "     'competition_distance',\n",
    "     'competition_open_since_month',\n",
    "     'competition_open_since_year',\n",
    "     'promo2',\n",
    "     'promo2_since_week',\n",
    "     'promo2_since_year',\n",
    "     'competition_time_month',\n",
    "     'promo_time_week',\n",
    "     'month_cos',\n",
    "     'day_sin',\n",
    "     'day_cos',\n",
    "     'week_of_year_cos',\n",
    "     'day_of_week_sin',\n",
    "     'day_of_week_cos']\n",
    "\n",
    "# columns to add\n",
    "feat_to_add = ['date', 'sales']\n",
    "cols_selected_boruta_full = cols_selected_boruta.copy()\n",
    "cols_selected_boruta_full.extend( feat_to_add )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7.0 Machine Learning Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = X_train[cols_selected_boruta]\n",
    "x_test = X_test[cols_selected_boruta]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.1 Average Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aux1 = x_test.copy()\n",
    "aux1['sales'] = y_test.copy()\n",
    "\n",
    "# prediction\n",
    "aux2 = aux1[['store','sales']].groupby('store').mean().reset_index().rename(columns={'sales': 'predictions'})\n",
    "aux1 = pd.merge(aux1, aux2, how='left', on='store')\n",
    "yhat_baseline = aux1['predictions']\n",
    "# performance\n",
    "baseline_result = ml_error( 'Average Model', np.expm1(y_test), np.expm1(yhat_baseline) )\n",
    "baseline_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.2 Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model \n",
    "lr = LinearRegression().fit( x_train, y_train) \n",
    "# prediction \n",
    "yhat_lr = lr.predict(x_test)\n",
    "# performance \n",
    "lr_result = ml_error ( 'Linear Regression',  np.expm1(y_test),  np.expm1(yhat_lr))\n",
    "lr_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.3 Linear Regression Regularized - Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model \n",
    "lrr = Lasso( alpha = 0.01 ).fit( x_train, y_train) \n",
    "\n",
    "# prediction \n",
    "yhat_lrr = lrr.predict(x_test)\n",
    "\n",
    "# performance \n",
    "lrr_result = ml_error ( 'Linear Regression - Lasso',  np.expm1(y_test),  np.expm1(yhat_lrr))\n",
    "lrr_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.4 Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model \n",
    "rf = RandomForestRegressor(n_estimators=100, n_jobs=-1, random_state=42).fit( x_train, y_train) \n",
    "\n",
    "# prediction \n",
    "yhat_rf = rf.predict(x_test)\n",
    "\n",
    "# performance \n",
    "rf_result = ml_error ( 'Random Forest Regressor',  np.expm1(y_test),  np.expm1(yhat_rf))\n",
    "rf_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.5 XGBoost Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model \n",
    "model_xgb = xgb.XGBRegressor( objective='reg:squarederror',\n",
    "                              n_estimators=100,\n",
    "                              eta=0.01,\n",
    "                              max_depth=10,\n",
    "                              subsample=0.7,\n",
    "                              colsample_bytree=0.9).fit( x_train, y_train) \n",
    "\n",
    "# prediction \n",
    "yhat_xgb = model_xgb.predict(x_test)\n",
    "\n",
    "# performance \n",
    "xgb_result = ml_error ( 'XGBoost Regressor',  np.expm1(y_test),  np.expm1(yhat_xgb))\n",
    "xgb_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.6 Compare Model Performance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelling_result = pd.concat( [baseline_result, lr_result, lrr_result, rf_result, xgb_result] )\n",
    "modelling_result.sort_values('RMSE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation( x_training, kfold, model_name, model, verbose=False ):\n",
    "        mae_list = []\n",
    "        mape_list=[]\n",
    "        rmse_list=[]\n",
    "        for k in reversed( range(1, kfold+1) ):\n",
    "            if verbose:\n",
    "                print( '\\nKFold Number: {}' .format(k) )\n",
    "            # Start and End date for validation\n",
    "            validation_start_date = x_training['date'].max() - datetime.timedelta(days=k*6*7)\n",
    "            validation_end_date =  x_training['date'].max() - datetime.timedelta(days=(k-1)*6*7)\n",
    "            \n",
    "            # filtering dataset\n",
    "            \n",
    "            training = x_training[x_training['date'] < validation_start_date]\n",
    "            validation = x_training[(x_training['date'] >= validation_start_date) & (x_training['date'] <= validation_end_date)]\n",
    "            \n",
    "            # training and validation dataset\n",
    "            \n",
    "            # training\n",
    "            xtraining = training.drop( ['date', 'sales'], axis=1 )\n",
    "            ytraining = training['sales']\n",
    "            # validation\n",
    "            xvalidation = validation.drop( ['date', 'sales'], axis=1 )\n",
    "            yvalidation = validation['sales']\n",
    "            \n",
    "            # model\n",
    "            m = model.fit( xtraining, ytraining )\n",
    "            # prediction\n",
    "            yhat = m.predict( xvalidation )\n",
    "            # performance\n",
    "            m_result = ml_error( model_name, np.expm1(yvalidation), np.expm1(yhat) ) \n",
    "            # store performance of each kfold iteration\n",
    "            mae_list.append(m_result['MAE'])\n",
    "            mape_list.append(m_result['MAPE'])\n",
    "            rmse_list.append(m_result['RMSE'])\n",
    "    \n",
    "        return pd.DataFrame({'Model Name': model_name,\n",
    "                      'MAE CV': np.round( np.mean(mae_list),2 ).astype( str ) + ' +/- ' + np.round( np.std(mae_list),2 ).astype(str),\n",
    "                      'MAPE CV': np.round( np.mean(mape_list),2 ).astype( str ) + ' +/- ' + np.round( np.std(mape_list),2 ).astype(str),\n",
    "                      'RMSE CV': np.round( np.mean(rmse_list),2 ).astype( str ) + ' +/- ' + np.round( np.std(rmse_list),2 ).astype(str)}, index=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_training = X_train[ cols_selected_boruta_full]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression()\n",
    "a = cross_validation( x_training, 5, 'Linear Regression', model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>MAE CV</th>\n",
       "      <th>MAPE CV</th>\n",
       "      <th>RMSE CV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>2079.28 +/- 303.04</td>\n",
       "      <td>0.3 +/- 0.02</td>\n",
       "      <td>2961.07 +/- 473.32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Model Name              MAE CV       MAPE CV             RMSE CV\n",
       "0  Linear Regression  2079.28 +/- 303.04  0.3 +/- 0.02  2961.07 +/- 473.32"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Lasso()\n",
    "a = cross_validation( x_training, 5, 'Lasso', model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>MAE CV</th>\n",
       "      <th>MAPE CV</th>\n",
       "      <th>RMSE CV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lasso</td>\n",
       "      <td>2388.68 +/- 398.48</td>\n",
       "      <td>0.34 +/- 0.01</td>\n",
       "      <td>3369.37 +/- 567.55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Model Name              MAE CV        MAPE CV             RMSE CV\n",
       "0      Lasso  2388.68 +/- 398.48  0.34 +/- 0.01  3369.37 +/- 567.55"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
